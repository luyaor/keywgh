<!DOCTYPE html>
<html lang="en"><!-- MathJax Support -->
   <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>“Modern Maximum-Likelihood Theory for High-Dimensional Logistic Regression” | Homepage</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="“Modern Maximum-Likelihood Theory for High-Dimensional Logistic Regression”" />
<meta name="author" content="Ganghua Wang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Speaker: Pragya Sur (Harvard University)" />
<meta property="og:description" content="Speaker: Pragya Sur (Harvard University)" />
<link rel="canonical" href="http://localhost:4000/seminar/2019/09/19/Maximum-Likelihood-Theory-for-High-Dimensional-Logistic-Regression.html" />
<meta property="og:url" content="http://localhost:4000/seminar/2019/09/19/Maximum-Likelihood-Theory-for-High-Dimensional-Logistic-Regression.html" />
<meta property="og:site_name" content="Homepage" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-09-19T11:00:55-05:00" />
<script type="application/ld+json">
{"url":"http://localhost:4000/seminar/2019/09/19/Maximum-Likelihood-Theory-for-High-Dimensional-Logistic-Regression.html","headline":"“Modern Maximum-Likelihood Theory for High-Dimensional Logistic Regression”","dateModified":"2019-09-19T11:00:55-05:00","datePublished":"2019-09-19T11:00:55-05:00","author":{"@type":"Person","name":"Ganghua Wang"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/seminar/2019/09/19/Maximum-Likelihood-Theory-for-High-Dimensional-Logistic-Regression.html"},"description":"Speaker: Pragya Sur (Harvard University)","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Homepage" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Homepage</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/teach/">Teaching</a><!-- <form id="search" role="search" action="/search/">    <input type="text" name="q" placeholder="Search" />  </form> -->
        </div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
           <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">“Modern Maximum-Likelihood Theory for High-Dimensional Logistic Regression&quot;</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2019-09-19T11:00:55-05:00" itemprop="datePublished">Sep 19, 2019
      </time></p>
  </header>


  <div class="post-content e-content" itemprop="articleBody">
    <p>Speaker: Pragya Sur (Harvard University)</p>

<h3 id="background">Background</h3>

<p>Logistic regression model, mainly for binary data.</p>

<p>$\mathbb{P}(y=1 \vert X)=\frac{e^{b^TX}}{1+e^{b^TX}}$</p>

<p>Classic MLE results, for fixed p, we have $\sqrt{n}(\hat{\beta}-\beta)\to N(0, I^{-1})$</p>

<p>​	 hypothesis testing, Wilks theorem.</p>

<p>how about diverging p? Some references.</p>

<h3 id="data">Data:</h3>

<p>Inspiration: 100~1000 sample size, 10~100 features. p close to n. When n/p is 5~10, can we trust results?</p>

<p>Obeservation: MLE will have systematic shift on both magnitudes and variance. Wilks theorem failed as well.</p>

<p>When finite sample, do correction. Like LRT first order correction. $\mathbb{E}(-2 lnLRT) \sim 1+\frac{\alpha}{n}+O(1/n^2)$, which not enough for high dimension.</p>

<h3 id="high-dimensional-behaviorp-n-to-infty-pn-text-to-a-constant--kappa">High dimensional behavior($p, n \to \infty, p/n \text{ to a constant } \kappa$).</h3>

<p>$\hat{\beta}-\alpha\beta\to N(0, \sigma^2_{h.d})$, which has a larger variance than classical result.</p>

<p>$-2lnLRT \sim r\chi^2, r&gt;1$</p>

<p>Some assumptions, like Signal strength $\gamma$ should be strong enough(converge to a constant), $\sqrt{n}X_i \sim N(0, I)$ .</p>

<p>When $\kappa$ is large, MLE may doesn’t exist. Associated with $\kappa, \gamma$, soltuion could be characterized as $\alpha, \sigma, \lambda$, which decide the final behavior.</p>

<h3 id="results">Results:</h3>

<p>Given the asymptotical behaive for mle estimators and LRT in this case.</p>

<p>Interpretation of $\lambda$, $r$ can be represented by $\sigma, \lambda$, and $\lambda$ captures the trace of Hessian matrix for estimation in high dimension.</p>

<h3 id="some-tools">Some Tools:</h3>

<p>robust M-estimation</p>

<p>Leave-one-out argument for \beta distribution</p>

<h3 id="extension-to-penalty-estimator">Extension to penalty estimator</h3>

<p>Distribution follows the proximal of penalty function with proper parameters.</p>

  </div><a class="u-url" href="/seminar/2019/09/19/Maximum-Likelihood-Theory-for-High-Dimensional-Logistic-Regression.html" hidden></a>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Contact</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ganghua Wang</li><li><a class="u-email" href="mailto:wang9019@umn.edu">wang9019@umn.edu</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"> <ul class="social-media-list"><a href="https://github.com/keywgh"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username"></span></a></ul> 
</div>

      <div class="footer-col footer-col-3">
        <p>Nice to meat you.</p>
      </div>
    </div>

  </div>

</footer>
<!----><!-- <script>
if(!(window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1")) {
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-141229469-1', 'auto');
  ga('send', 'pageview');
}
</script>
  
 -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-141229469-1', 'auto');
  ga('send', 'pageview');

</script></body>

</html>
